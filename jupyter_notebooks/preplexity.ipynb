{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f5f34d-4616-453c-a3e5-a0e0a7904882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51d9c847ce24a0e97abc4aa5d9df9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Set up device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = \"microsoft/phi-4\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "def calculate_perplexity(text, model_name=\"microsoft/phi-4\"):\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of an LLM given a text input.\n",
    "    Perplexity = exp(average negative log-likelihood per token)\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to calculate perplexity for\n",
    "        model_name (str): Name of the HuggingFace model to use\n",
    "        \n",
    "    Returns:\n",
    "        float: The perplexity score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Encode the text\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Get the sequence length and model's maximum context length\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "    max_length = min(model.config.max_position_embeddings, 2048)  # Use model's max or cap at 2048\n",
    "    \n",
    "    # For perplexity calculation, we'll use a sliding window approach if the text is long\n",
    "    stride = max(1, max_length // 2)  # Use half the max length as stride for efficiency\n",
    "    \n",
    "    # Initialize variables to track the cumulative negative log-likelihood and token count\n",
    "    nlls = []\n",
    "    total_tokens = 0\n",
    "    \n",
    "    # Process the text in chunks with sliding window\n",
    "    for i in tqdm(range(0, seq_len, stride)):\n",
    "        # Define the chunk boundaries\n",
    "        begin_loc = i\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        \n",
    "        # Extract the chunk\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc]\n",
    "        \n",
    "        # Create targets by shifting inputs to the right\n",
    "        # This is how we set up the task for the model to predict the next token\n",
    "        target_ids = input_ids.clone()\n",
    "        \n",
    "        # Calculate loss\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            neg_log_likelihood = outputs.loss.item()\n",
    "        \n",
    "        # The model calculates average loss, so we need to multiply by the number of tokens\n",
    "        # to get total loss, subtracting 1 to account for the label shifting\n",
    "        num_tokens = end_loc - begin_loc - 1\n",
    "        total_loss = neg_log_likelihood * num_tokens\n",
    "        \n",
    "        nlls.append(total_loss)\n",
    "        total_tokens += num_tokens\n",
    "        \n",
    "        # If we've reached the end of the sequence, break\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "    \n",
    "    # Calculate average negative log-likelihood\n",
    "    avg_nll = sum(nlls) / total_tokens if total_tokens > 0 else 0\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    perplexity = torch.exp(torch.tensor(avg_nll))\n",
    "    \n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c1f93a-8f8b-406c-a915-e7ca8b499b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                          | 0/1 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1066.717529296875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_perplexity(\"I strive for da gold...  And pic my own shit. Move bricks ill break and go pitch da whole load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3902fb1-19d3-47f8-b983-31e6eb51162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                          | 0/1 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "224.47000122070312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_perplexity(\"I strive for the gold... And choose my own things. Move bricks Iâ€™ll break and then go sell the whole load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628dd5e7-8162-44f0-9703-7bc9c578cdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
